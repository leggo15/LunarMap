{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script was made after the exam concluded.\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def get_category_members(category):\n",
    "    session = requests.Session()\n",
    "    url = 'https://en.wikipedia.org/w/api.php'\n",
    "    members = []\n",
    "\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'list': 'categorymembers',\n",
    "        'cmtitle': category,\n",
    "        'cmlimit': '500'\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        response = session.get(url=url, params=params)\n",
    "        data = response.json()\n",
    "        members.extend(data['query']['categorymembers'])\n",
    "\n",
    "        if 'continue' in data:\n",
    "            params['cmcontinue'] = data['continue']['cmcontinue']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return members\n",
    "\n",
    "def clean_coordinates(coord_str):\n",
    "    normalized_str = re.sub(r'[^\\x00-\\x7F]+', ' ', coord_str)\n",
    "    pattern = re.compile(r\"(\\d+\\.\\d+)\\s*([NS])[\\s;,/]*\\s*(\\d+\\.\\d+)\\s*([EW])\")\n",
    "    match = pattern.search(normalized_str)\n",
    "    if match:\n",
    "        lat, lat_dir, lon, lon_dir = match.groups()\n",
    "        lat = float(lat) * (-1 if lat_dir == 'S' else 1)\n",
    "        lon = float(lon) * (-1 if lon_dir == 'W' else 1)\n",
    "        return [lon, lat]\n",
    "    return None\n",
    "\n",
    "def convert_diameter_to_fraction(diameter_str, lunar_radius_km=1737.4):\n",
    "    try:\n",
    "        # Use a regular expression to extract the kilometers part from the string\n",
    "        km_match = re.search(r\"(\\d+(\\.\\d+)?)\\s*km\", diameter_str)\n",
    "        if km_match:\n",
    "            # If km is found, use it\n",
    "            diameter_km = float(km_match.group(1))\n",
    "        else:\n",
    "            # Check if the diameter is given in meters instead\n",
    "            m_match = re.search(r\"(\\d+(\\.\\d+)?)\\s*m\", diameter_str)\n",
    "            if m_match:\n",
    "                # Convert from meters to kilometers\n",
    "                diameter_km = float(m_match.group(1)) / 1000\n",
    "            else:\n",
    "                return 0  # Return 0 if no valid diameter is found\n",
    "\n",
    "        # Convert diameter in km to a fraction of the lunar radius\n",
    "        return (diameter_km / lunar_radius_km) / 0.17843\n",
    "    except (TypeError, AttributeError, ValueError):\n",
    "        return 0  # Return 0 if there's an issue with the conversion\n",
    "\n",
    "\n",
    "def clean_name(name):\n",
    "    return re.sub(r'\\s*\\((lunar\\s+)?crater\\)', '', name, flags=re.IGNORECASE)\n",
    "\n",
    "def fetch_first_large_image_url_from_wiki(page_title):\n",
    "    url = f\"https://en.wikipedia.org/wiki/{page_title.replace(' ', '_')}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    images = soup.find_all('img')\n",
    "\n",
    "    # Known URL or pattern of the red question mark image\n",
    "    red_question_mark = \"Text_document_with_red_question_mark.svg\"\n",
    "\n",
    "    for img in images:\n",
    "        src = img.get('src', '')\n",
    "        if src.startswith(\"//\"):  # Correct relative URLs\n",
    "            src = \"https:\" + src\n",
    "\n",
    "        # Skip the red question mark image\n",
    "        if red_question_mark in src:\n",
    "            continue  # Ignore this image and continue with the next one\n",
    "\n",
    "        # Check if the image is suitable (i.e., hosted on Wikimedia Commons and is in an appropriate format)\n",
    "        if 'upload.wikimedia.org/wikipedia/commons' in src and ('thumb' in src or 'b/b4' in src):\n",
    "            if any(ext in src for ext in ['.jpg', '.jpeg', '.png']):\n",
    "                return src\n",
    "\n",
    "    return \"No suitable image found\"\n",
    "\n",
    "\n",
    "def fetch_crater_data(page_title):\n",
    "    data = {\n",
    "        'name': clean_name(page_title.replace('_', ' ')),\n",
    "        'Wiki': f\"https://en.wikipedia.org/wiki/{page_title.replace(' ', '_')}\",\n",
    "        'image_url': fetch_first_large_image_url_from_wiki(page_title)  # Fetch the first large image directly\n",
    "    }\n",
    "    url = data['Wiki']\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    infobox = soup.find('table', class_='infobox')\n",
    "\n",
    "    if infobox:\n",
    "        for row in infobox.find_all('tr'):\n",
    "            header = row.find('th')\n",
    "            value = row.find('td')\n",
    "            if header and value:\n",
    "                header_text = header.text.strip()\n",
    "                value_text = value.text.strip()\n",
    "                if header_text == 'Coordinates':\n",
    "                    data['coordinates'] = clean_coordinates(value_text) or \"Not found\"\n",
    "                elif header_text.lower() == 'diameter':\n",
    "                    data['radius'] = convert_diameter_to_fraction(value_text)\n",
    "                elif header_text.lower() == 'depth':\n",
    "                    data['depth'] = value_text\n",
    "                elif header_text.lower() == 'eponym':\n",
    "                    data['eponym'] = value_text\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_data_to_geojson(data, filename='craters.geojson'):\n",
    "    geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": []\n",
    "    }\n",
    "    for entry in data:\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {\n",
    "                \"name\": entry.get('name'),\n",
    "                \"Wiki\": entry.get('Wiki', ''),\n",
    "                \"numPoints\": 16,\n",
    "                \"radius\": entry.get('radius', 0),\n",
    "                \"depth\": entry.get('depth', 'Unknown'),\n",
    "                \"eponym\": entry.get('eponym', 'Unknown'),\n",
    "                \"image_url\": entry.get('image_url', 'No image available')\n",
    "            },\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": entry.get('coordinates', [])\n",
    "            }\n",
    "        }\n",
    "        geojson['features'].append(feature)\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(geojson, f, indent=4)\n",
    "\n",
    "category = 'Category:Impact_craters_on_the_Moon'\n",
    "members = get_category_members(category)\n",
    "crater_data = [fetch_crater_data(member['title']) for member in members]\n",
    "\n",
    "save_data_to_geojson(crater_data)\n",
    "print(\"GeoJSON data for all craters has been fetched and saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
